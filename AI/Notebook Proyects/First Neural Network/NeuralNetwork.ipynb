{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP IAR 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import csv\n",
    "import pickle\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    " \n",
    "def sigmoid_derivada(x):\n",
    "    return sigmoid(x)*(1.0-sigmoid(x))\n",
    " \n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    " \n",
    "def tanh_derivada(x):\n",
    "    return 1.0 - x**2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    " \n",
    "    #Función constructora\n",
    "    def __init__(self, layers, activation='tanh'):\n",
    "        #Posibles funciones de activación (Se peuden agregar otras como relu, pero las entradas van de 0 a 10, no vale la pena)\n",
    "        if activation == 'sigmoid':\n",
    "            self.activation = sigmoid\n",
    "            self.activation_prime = sigmoid_derivada\n",
    "        elif activation == 'tanh':\n",
    "            self.activation = tanh\n",
    "            self.activation_prime = tanh_derivada\n",
    " \n",
    "        # inicializo los vectores de pesos y errores de dichos pesos\n",
    "        self.weights = []\n",
    "        self.deltas = []\n",
    "        # rando de pesos varia entre (-1,1)\n",
    "        # asigno valores aleatorios a las capas\n",
    "        for i in range(1, len(layers) - 1):\n",
    "            r = 2*np.random.random((layers[i-1]+1, layers[i]+1)) -1\n",
    "            self.weights.append(r)\n",
    "        # asigno aleatorios a capa de salida\n",
    "        r = 2*np.random.random( (layers[i]+1, layers[i+1])) - 1\n",
    "        self.weights.append(r)\n",
    "        \n",
    " \n",
    "\n",
    "    #Función de entrenamiento\n",
    "    def fit(self, X, y, learning_rate=0.0, epochs=1):\n",
    "        \n",
    "        # Con esto agregamos el vector unitario a la capa de entrada\n",
    "        X = np.hstack((X, np.ones((X.shape[0],1))))\n",
    "        \n",
    "         \n",
    "        for k in range(epochs):\n",
    "            # Elegimos una entrada aleatoria dentro del conjunto\n",
    "            i = np.random.randint(0, X.shape[0]-1)\n",
    "            a = [X[i]]\n",
    "            \n",
    "            #Capa de entrada\n",
    "            for l in range(len(self.weights)):\n",
    "                # Producto escalar entre arrays de cada valor de entrada por el peso correspondiente\n",
    "                dot_value = np.dot(a[l], self.weights[l])\n",
    "                # Aplicar función de activación\n",
    "                activation = self.activation(dot_value)\n",
    "                # Agregar a \"a\"\n",
    "                a.append(activation)\n",
    "            \n",
    "            # Calculo la diferencia en la capa de salida y el valor obtenido\n",
    "            error = y[i] - a[-1]\n",
    "            # Guardo el error en Deltas con el inverso de la función de activación\n",
    "            deltas = [error * self.activation_prime(a[-1])]\n",
    "            \n",
    "            # Analizamos las demás capas\n",
    "            for l in range(len(a) - 2, 0, -1): \n",
    "                #Calculamos el error de la misma manera\n",
    "                deltas.append(deltas[-1].dot(self.weights[l].T)*self.activation_prime(a[l]))\n",
    "            #Agregamos el delta \n",
    "            self.deltas.append(deltas)\n",
    " \n",
    "            # invertimos los deltas para aplicar backpropagation\n",
    "            deltas.reverse()\n",
    " \n",
    "            # Comenzamos el algoritmo de backpropagation\n",
    "            # 1. Multiplcamos los delta de salida con las activaciones de entrada \n",
    "            #    para obtener el gradiente del peso.\n",
    "            # 2. Actualizamos el peso en base al ratio de aprendizaje multiplicado por el gradiente\n",
    "            for i in range(len(self.weights)):\n",
    "                #convertimos el array analizado y los deltas en 2 dimensiones. [[]]\n",
    "                layer = np.atleast_2d(a[i])\n",
    "                delta = np.atleast_2d(deltas[i])\n",
    "                self.weights[i] += learning_rate * layer.T.dot(delta)\n",
    "            \n",
    "            # Mostrar cada cuerto porcentaje de de las iteraciones un mensaje para informar avance\n",
    "            if k % (epochs/10) == 0: \n",
    "                print(\"Entrenando: \", int(k/epochs*100), \"%\", sep=\"\")\n",
    " \n",
    "    \n",
    "    #Función predictiva en base a los pesos entrenados en fit()\n",
    "    def predict(self, x): \n",
    "        \n",
    "        # Crear vector de unos y concatenarlo a la entrada\n",
    "        ones = np.atleast_2d(np.ones(x.shape[0]))\n",
    "        a = np.hstack((x, np.ones((x.shape[0],1))))\n",
    "        # Pasamos el vector generado por todas las capas (Teniendo en cuenta la función de activación)\n",
    "        for l in range(0, len(self.weights)):\n",
    "            a = self.activation(np.dot(a, self.weights[l]))\n",
    "        \n",
    "        #Acomodamos las salidas al formato requerido\n",
    "        res = []\n",
    "        for r in range(0, len(a)):\n",
    "            res.append(a[r][0])\n",
    "        res = np.array(res)\n",
    "        # Devolvemos el generado por las capas de salida en formato binario\n",
    "        # El valor fue obtenido de manera empírica, obteniendo mejores resultados que con .5 (propuesto)\n",
    "        return np.heaviside(res -.49, np.zeros(res.shape))\n",
    " \n",
    "\n",
    "    # Imprimir los pesos\n",
    "    def print_weights(self):\n",
    "        print(\"LISTADO PESOS DE CONEXIONES\")\n",
    "        for i in range(len(self.weights)):\n",
    "            print(self.weights[i])\n",
    " \n",
    "    # Obtener los errores\n",
    "    def get_deltas(self):\n",
    "        return self.deltas\n",
    "    \n",
    "    def save_params(self, nombre=\"params\"):\n",
    "        pickle_file = open(nombre + \".pickle\", 'wb')\n",
    "        pickle.dump(self.weights, pickle_file)\n",
    "        #pickle.dump(self.weights, open(nombre + \".pickle\", \"wb\"))\n",
    "        \n",
    "    def load_params(self, nombre=\"params\"):\n",
    "        pickle_file = open(nombre + \".pickle\", \"rb\")\n",
    "        self.weights = pickle.load(pickle_file)\n",
    "#         with open(nombre + \".pickle\", 'rb') as f:\n",
    "#             file = pickle.load(f)\n",
    "#             print(\"file 0: \", np.array(file[0]))\n",
    "#             print(\"file 1: \", np.array(file[1]))\n",
    "#             self.weights = np.append(np.atleast_2d(np.array(file[0])), np.atleast_2d(np.array(file[1])))\n",
    "#             print(\"we: \", self.weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leemos los archivos de entrenamiento y los guardamos\n",
    "X = np.genfromtxt('X.csv', delimiter=',')\n",
    "Y = np.genfromtxt('Y.csv', delimiter=',')\n",
    "\n",
    "# Creamos variables para separar un 70% de los datos para entrenar y 30% para prueba interna\n",
    "XRED = []\n",
    "YRED = []\n",
    "XTEST = []\n",
    "YTEST = []\n",
    "for i in range(0,20000):\n",
    "    ran = np.random.rand()\n",
    "    if (ran < .7):\n",
    "    #if(i < 14000):\n",
    "        XRED.append(X[i])\n",
    "        YRED.append(Y[i])\n",
    "    else:\n",
    "        XTEST.append(X[i])\n",
    "        YTEST.append(Y[i])\n",
    "\n",
    "XRED =  np.array(XRED)\n",
    "YRED =  np.array(YRED)\n",
    "XTEST = np.array(XTEST)\n",
    "YTEST = np.array(YTEST)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador = NeuralNetwork([4,100,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Presición: 0.77685\n"
     ]
    }
   ],
   "source": [
    "#Datos de entrenamiento completos\n",
    "clasificador.fit(X,Y,learning_rate=0.04,epochs=100000)\n",
    "res = clasificador.predict(X)\n",
    "# Evaluación del clasificador para los datos de entrenamiento\n",
    "cant_datos = X.shape[0]\n",
    "accuracy = (cant_datos - abs(res - Y).sum())/cant_datos\n",
    "clear_output(wait=True)\n",
    "print(\"Presición:\", accuracy)\n",
    "\n",
    "# También usamos este bloque para probar ajustes ligeros en la red sin tener que esperar mucho tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la instancia de la Red\n",
    "clasif = NeuralNetwork([4,8,16,8,4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Entrenamiento finalizado...\nPrecisión entrenamiento: 0.9845187986016979\nMatriz de confusión entrenamiento:  [[6875, 93], [124, 6925]]\nPrecisión test (no cátedra): 0.9839545378572623\nMatriz de confusión test (no cátedra):  [[2986, 46], [50, 2901]]\n"
     ]
    }
   ],
   "source": [
    "#Datos separados\n",
    "\n",
    "#Entrenamos la red con los datos reducidos (70%) \n",
    "print(\"Preparando la red para entrenamiento...\")\n",
    "clasif.fit(XRED,YRED,learning_rate=0.0,epochs=1)\n",
    "clear_output(wait=True)\n",
    "print(\"Entrenamiento finalizado...\")\n",
    "\n",
    "# Evaluamos la red neuronal para los datos de entrenamiento\n",
    "res = clasif.predict(XRED)\n",
    "cant_datos = XRED.shape[0]\n",
    "mat_conf = [[0,0],[0,0]]\n",
    "for i in range(0,XRED.shape[0]):\n",
    "    mat_conf[int(YRED[i])][int(res[i])] += 1\n",
    "accuracy = (cant_datos - abs(res - YRED).sum())/cant_datos\n",
    "print(\"Precisión entrenamiento:\", accuracy)\n",
    "print(\"Matriz de confusión entrenamiento: \", mat_conf)\n",
    "\n",
    "# Evaluamos la red neuronal para los datos de test (no cátedra)\n",
    "res_test = clasif.predict(XTEST)\n",
    "cant_datos_test = XTEST.shape[0]\n",
    "mat_conf_test = [[0,0],[0,0]]\n",
    "for i in range(0,XTEST.shape[0]):\n",
    "    mat_conf_test[int(YTEST[i])][int(res_test[i])] += 1\n",
    "accuracy_test = (cant_datos_test - abs(res_test - YTEST).sum())/cant_datos_test\n",
    "print(\"Precisión test (no cátedra):\", accuracy_test)\n",
    "print(\"Matriz de confusión test (no cátedra): \", mat_conf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validación de la cátedra y exportación de resultados y parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_catedra = np.genfromtxt('X_test.csv', delimiter=',')\n",
    "# preprocesamiento si es necesario...........\n",
    "res_test_catedra = clasif.predict(X_test_catedra)\n",
    "np.savetxt('Y_test_Grupo_08.csv', res_test_catedra, delimiter=',')\n",
    "clasif.save_params(\"params_Grupo_08\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métodos Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tener en cuenta que la red entrenada con epochs=30000000 se realizó con una memoria RAM de 16Gb... Se puede adaptar corriendo varias veces y utilizando el save/load params con iteraciones más cortas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif.save_params(\"params_Grupo_08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasif.load_params(\"params_Grupo_08\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LISTADO PESOS DE CONEXIONES\n[[ 4.77063178e-01  2.68000079e+00 -1.40143757e+00  2.26447800e+00\n   1.84022827e-02 -1.68690706e-02 -2.20446320e+00 -3.51701540e+00\n   5.49004784e-03  2.46784389e+00  6.65332702e-01  7.65824173e-01\n   1.45002363e+00 -1.44546430e-02  1.16016842e+00 -6.04288500e-01\n  -1.37805859e+00 -2.57257389e-01  2.62846054e-01 -2.18106957e+00\n  -3.30544776e-01  1.34116461e+00 -8.33668537e-01  5.23295589e-01\n   7.45237993e-02  1.15561917e+00  4.59463554e-02  5.05770292e-03\n   1.47201279e-02 -8.11997418e-01 -7.28917255e-01  6.30655064e-01\n  -9.31184402e-01 -4.38733524e-03  6.16045442e-01 -1.47190732e+00\n   1.24823268e-03  3.56215913e-02 -1.97721780e+00  1.09177769e+00\n  -4.20780753e-03  1.02385533e+00 -3.30862644e+00  8.77338342e-01\n   1.44571658e-01  1.38321019e+00  4.94779132e+00 -3.40612225e-01\n  -3.64124149e-01  4.21180609e+00  3.27370995e-03  1.81739923e+00\n   7.21239243e-04 -2.04307243e+00  5.80229430e-01 -1.13491889e-02\n   1.98660478e+00 -7.14626606e-01 -4.49172276e-01 -1.03867704e+00\n  -7.97594425e-03 -8.08198161e-01  8.73631842e-03 -3.89186262e+00\n   9.81951693e-01  2.06785060e+00 -8.05518039e-02  4.43067341e-01\n   2.63359631e-01  3.27012970e-02 -2.66484874e-02 -1.67917129e-01\n  -6.03774298e-03 -1.10012539e-01 -9.65201823e-01 -1.39603969e+00\n   3.14395374e+00 -8.60613636e-01 -2.18093051e+00 -4.65543356e-01\n   1.84228133e+00  1.30311466e+00  2.27702784e-02  1.82764054e+00\n  -1.59003334e+00 -1.41298929e+00 -4.51201713e+00  6.65909890e-01\n   3.90238172e+00 -3.83811388e-01 -6.09975231e+00  4.76215992e-03\n   9.57427396e-01 -5.69614856e-01  1.51327150e-01 -1.99368861e+00\n  -1.40742412e+00 -2.59775114e-01  7.52031494e-01  3.40852951e+00\n   2.35934620e+00]\n [ 4.38903658e-01  1.45161865e-01 -2.24752193e-01  2.12883738e+00\n   2.84196559e-02 -2.61994449e-02  3.73617463e+00  7.18966743e-01\n   9.88294779e-01  3.47668527e-01  1.08615122e+00 -1.02552786e+00\n  -4.27546051e+00 -2.26332628e-02 -1.35082634e+00 -5.73054097e-01\n   4.59475214e+00 -8.90306018e-01  6.98582935e-01  1.56256486e+00\n  -2.31224074e-01  1.56064651e+00 -4.79486414e-01  4.64010402e-01\n   2.51146011e-01 -2.75758989e+00 -3.09279779e+00  8.08535179e-03\n   2.30294484e-02 -7.37646467e-02  1.23134664e+00  4.63054591e-01\n  -9.01504276e-01 -7.01884362e-03  6.94449504e-01  2.56437491e-01\n   2.00103167e-03  5.13345602e-02  2.71407360e+00 -9.51037932e-01\n  -6.73284240e-03 -1.39040903e+00 -3.55882916e+00  2.44455007e-01\n  -2.89904909e+00  2.07302282e-01  3.10619749e+00 -6.40830912e+00\n  -4.20047727e-01  1.37943397e+00  5.24246544e-03 -1.01469143e+00\n   1.15635258e-03  7.74784059e-01  1.03613258e+00 -1.79298174e-02\n  -7.28938894e-01 -1.68666406e+00 -2.43697214e+00  6.60143761e-01\n  -1.26946178e-02 -2.89399777e+00  1.38845671e-02  3.35545790e+00\n  -3.71417940e-01 -2.41022013e+00 -2.65094021e-01 -3.56754568e-02\n   8.05478602e-01 -1.33334417e-02 -1.13705995e+00  3.61139787e-01\n  -9.63991508e-03 -2.10406338e-01 -6.23637660e-01 -1.17877359e+00\n  -2.32148285e+00 -5.72947869e-01  5.89979235e-01  8.53223086e-02\n  -2.94070686e+00 -1.33503242e+00  6.75047417e-01  1.71387332e+00\n   3.01155543e+00  1.80240068e+00  4.80760416e+00  4.80689793e-01\n  -6.05710147e-01 -5.55271450e-01  4.28700347e+00  7.55251132e-03\n   1.13933370e+00 -9.46877632e-01  2.55467720e+00 -2.08873271e+00\n   6.14106659e-01 -6.01098949e-01  5.68849419e-01  1.79797146e+00\n   4.30726751e-01]\n [ 5.43807332e-01 -2.71581949e-02 -1.95989665e-02 -2.79780694e-02\n   8.77229852e-03 -7.96396288e-03  2.43861721e-03  6.57325178e-06\n   6.52977375e-01 -1.51890254e-02 -2.68318968e-02 -7.94399340e-01\n  -4.79326324e-02 -6.72893605e-03  8.49087844e-02 -7.18035104e-02\n  -7.33872681e-04 -4.70488587e-01  6.67200069e-01 -1.99374206e-02\n   1.57263998e-02 -8.91036899e-03 -9.11041998e-01  9.14872456e-02\n   6.63134666e-01 -1.21005850e+00 -4.02483744e-04  2.27052843e-03\n   6.86257022e-03 -6.93104777e-01  6.27157175e-01  8.88854321e-01\n  -4.14562396e-01 -1.96701832e-03  7.26500744e-01  5.61730856e-02\n   5.57590282e-04  1.91588275e-02 -1.86596861e-02  9.41032383e-03\n  -1.88592890e-03 -6.51091116e-01 -2.46483606e-03  9.13129475e-04\n   5.21108737e-03  3.05193465e-01 -2.02907638e-02 -1.58736808e-02\n   9.00709341e-03  5.78541667e-03  1.46515354e-03 -1.13563594e-03\n   3.22110992e-04 -1.74085555e-02  6.69467397e-01 -5.20204021e-03\n  -5.49269754e-02 -9.70396017e-03  3.14861698e-03 -4.73564153e-02\n  -3.60851781e-03  4.33821541e-03  3.96270003e-03  1.59577397e-02\n   9.96663568e-01 -3.30523761e-01 -2.03879191e-01  1.31713955e-01\n   9.71601305e-01  1.64814543e-03 -9.01864971e-01 -3.11836080e-01\n  -2.71654566e-03 -2.13541232e-01 -1.81178864e-03 -9.38740323e-03\n   2.55685741e-03  4.54512677e-01 -6.59107001e-01  1.07495833e-02\n  -3.83101261e-02  7.09868657e-03 -4.59388259e-02  5.30268223e-02\n  -2.81793336e-01 -1.12838840e-02 -7.01899436e-02  9.86187422e-02\n   2.73775885e-02  5.99641877e-02  1.21475769e-02  2.23551038e-03\n  -1.19814737e-02 -1.12427542e-01  3.12074424e-02  2.08794376e-02\n   3.28087002e-02 -7.37586830e-01  1.03743016e+00  4.15040703e-02\n   3.69990837e-03]\n [ 4.64717210e-02  5.28958371e-01 -4.89864307e-01 -2.28331909e+00\n   4.35230391e-02 -3.99393185e-02  1.46470430e+00  4.53102652e+00\n   2.47708536e+00 -2.61707932e+00 -4.54303917e-01  8.34275411e-01\n   5.36470940e+00 -3.42708464e-02  3.83850927e-01 -1.67832729e-01\n  -2.67786792e+00 -1.06840206e+00  5.92699664e-01  4.33251199e-01\n   2.51117057e+00 -2.17624964e+00 -2.87075769e-03  3.36620047e-01\n   1.97224785e-01  3.03224162e+00  5.15798555e+00  1.20231301e-02\n   3.48954968e-02 -9.50080428e-01 -1.56129776e+00  3.56578747e-01\n   9.55192885e-01 -1.04302056e-02  1.25063811e-01  3.12203259e+00\n   2.96797388e-03  8.31009835e-02 -3.69601447e+00 -4.85503557e-01\n  -1.00035592e-02  1.08242580e+00  4.22137679e+00  1.04326372e+00\n   3.26260334e+00  2.35471737e+00 -5.44837839e+00  5.43221507e+00\n  -3.05475409e+00 -2.95230239e+00  7.78337902e-03  4.63618124e-01\n   1.71493585e-03 -3.08269408e-01  1.86435833e-01 -2.69434994e-02\n  -2.84542321e+00  2.73840229e+00  2.36298213e+00  7.46866618e-01\n  -1.89522046e-02  2.51604902e+00  2.07556697e-02 -2.76618963e+00\n   5.13618700e+00  9.59010267e-01  8.34748837e-01  4.60159612e-01\n   4.95420249e-01  1.22030991e+00 -6.93150948e-02  4.39395309e-01\n  -1.43512432e-02 -1.45183076e+00 -1.43510113e-01 -6.01183718e-02\n  -3.01626459e+00  3.77872410e-01  3.01089661e+00 -1.29794909e-01\n  -2.11188627e+00 -7.76987924e-01 -4.75636088e-01 -3.61668316e+00\n  -1.44958845e+00 -3.68532047e+00 -5.67991472e+00  5.14191925e-01\n  -3.24482185e+00  2.13472388e+00  6.56560492e+00  1.06237251e-02\n  -2.60554553e+00 -7.32846653e-01 -4.68509776e-01  3.01868485e+00\n   2.04018210e+00 -6.42305799e-01 -2.78226850e-01 -6.23059343e+00\n  -2.53744082e+00]\n [ 7.72639324e-01 -7.23520118e-01 -7.63054272e-01 -3.66245522e+00\n  -4.70628862e-01  4.28902293e-01 -2.16269632e+00  7.41277913e-01\n   3.02269058e-01  2.25264158e-02 -5.38398657e+00  3.27468456e-01\n  -7.91173053e-01  3.64384886e-01 -5.90811901e-01  2.64829280e-01\n   2.12203698e+00  3.54279941e-01 -4.95978549e-01 -3.97129103e+00\n  -9.15942189e+00 -8.30218433e+00 -2.80900065e-01  4.59934412e-02\n   8.56363555e-01 -3.76534528e+00  1.41539611e-01 -1.24601873e-01\n  -3.71410732e-01 -8.58829238e-01  1.67223471e+00  8.50375930e-01\n  -6.84276567e-01  1.07993668e-01 -9.65322791e-01  1.16265296e+00\n  -3.06504687e-02 -9.92621877e-01 -1.95216361e-01 -1.63111530e-01\n   1.03552818e-01 -8.40899602e-01  1.78736260e+00 -1.01261542e+01\n   7.80600231e+00 -1.26655855e+00  7.96972496e-01 -8.84345672e+00\n   1.71835473e+01 -4.85370469e+00 -8.04878993e-02 -1.19939444e+01\n  -1.77075482e-02  2.13085399e+00 -8.43806417e-01  2.83362894e-01\n   4.50010039e+00 -1.83799161e-01  8.22554783e+00 -8.11940416e-01\n   1.97494197e-01  2.36480545e-03 -2.16680389e-01  3.97378039e-01\n   3.21444652e+00 -2.62021629e+00 -1.18599028e+00  8.47145667e-01\n   1.46327834e-02 -6.73857616e+00 -5.44114502e-01 -1.51953217e+00\n   1.48964594e-01 -1.18134158e+00  5.02897090e+00  3.97574566e+00\n   1.64888501e-01  1.75350118e+00 -6.72980522e+00  2.16045038e+00\n   5.90511937e+00 -5.50064577e-01  5.44783798e-01  2.32414841e+00\n   1.05873085e+00  5.43870891e-01  6.34408008e+00  7.54892462e-01\n   9.70537444e+00  1.83430117e+00 -1.71112791e-01 -1.14868288e-01\n  -3.38256989e+00 -2.60451140e-01 -5.10936728e+00  7.39555708e-01\n  -7.03282511e-01 -7.58396988e-01  7.84591872e-01  2.20986308e+00\n  -9.58909864e+00]]\n[[ 6.01547180e-01]\n [ 5.30812043e-01]\n [-8.23397246e-01]\n [ 2.67827895e-01]\n [ 2.17392026e-02]\n [-2.00645994e-02]\n [ 1.79778097e-01]\n [-2.51105977e-01]\n [ 3.22512169e-01]\n [-1.16854468e-01]\n [-3.95196460e-01]\n [ 3.72399907e-02]\n [-3.59796114e-01]\n [-1.73616661e-02]\n [ 8.33970757e-02]\n [ 3.23098138e-01]\n [-1.87388998e-02]\n [ 4.70343624e-01]\n [ 3.99422724e-01]\n [-1.72212124e-01]\n [ 4.96977984e-01]\n [ 4.90229775e-01]\n [ 5.64958028e-01]\n [-6.10352907e-01]\n [-8.28410629e-01]\n [ 8.14985769e-03]\n [ 2.82040502e-01]\n [ 6.22447904e-03]\n [ 1.76626765e-02]\n [-8.25578836e-01]\n [ 2.63871322e-02]\n [ 4.81277441e-01]\n [-3.75575989e-02]\n [-5.40402710e-03]\n [-3.14091633e-01]\n [-3.64973333e-02]\n [ 1.54112144e-03]\n [ 3.87392466e-02]\n [ 1.49469447e-01]\n [ 1.76797914e-02]\n [-5.18396412e-03]\n [-4.64244765e-02]\n [ 4.86945255e-01]\n [-4.91804305e-01]\n [ 4.03396994e-01]\n [ 6.22168593e-01]\n [-6.49273034e-01]\n [ 1.90846560e+00]\n [ 7.47724746e-01]\n [ 3.72785003e-01]\n [ 4.03692983e-03]\n [ 6.69447768e-01]\n [ 8.90595978e-04]\n [-2.38173388e-01]\n [ 4.04758189e-01]\n [-1.37764288e-02]\n [ 2.12434396e-01]\n [-3.08623140e-01]\n [-3.86070211e-01]\n [-1.98196802e-01]\n [-9.76620809e-03]\n [-2.31455256e-01]\n [ 1.06791229e-02]\n [-3.79747439e-01]\n [ 3.09541628e-01]\n [ 3.24464701e-02]\n [ 5.43254348e-02]\n [ 6.20220585e-01]\n [-5.50040882e-01]\n [ 7.28171816e-01]\n [-7.78529384e-01]\n [ 2.67654502e-02]\n [-7.41983389e-03]\n [-8.63323019e-01]\n [ 1.28879422e-01]\n [ 3.19343211e-01]\n [ 3.09855449e-01]\n [ 3.20620837e-02]\n [ 1.45330559e-02]\n [ 1.95113352e-01]\n [-3.05044412e-01]\n [-9.78042929e-02]\n [ 1.07098306e-01]\n [ 2.47619604e-01]\n [ 7.80109181e-02]\n [ 1.08102237e-01]\n [-2.33194342e-01]\n [ 1.77259767e-01]\n [-1.99930312e+00]\n [-7.30149130e-02]\n [ 3.42194955e-01]\n [ 5.66439414e-03]\n [-4.49706752e-01]\n [ 2.74631866e-01]\n [ 4.06952949e-01]\n [-1.70749057e-01]\n [ 1.99606093e-01]\n [ 3.35688625e-01]\n [ 7.58892027e-01]\n [ 9.93373213e-02]\n [-6.51578969e-01]]\n"
     ]
    }
   ],
   "source": [
    "clasif.print_weights() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento finalizado...\n",
      "Rate:  1.2514114379882814e-05\n",
      "Vuelta:  20\n",
      "Presición entrenamiento: 0.9803613511390417\n",
      "Presición test (no cátedra): 0.9726529931632483\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento iterativo\n",
    "rate=0.003\n",
    "accuracy = 0\n",
    "accuracy_test=0\n",
    "ac_test_ant = 0\n",
    "ac_ant = 0\n",
    "vuelta = 0\n",
    "while rate > 0.000001 and accuracy_test < 0.98 and accuracy - accuracy_test < .07 and vuelta < 20:\n",
    "    #Entrenamos la red con los datos reducidos (70%) \n",
    "    print(\"Preparando la red para entrenamiento...\")\n",
    "    clasif.fit(XRED,YRED,learning_rate=rate,epochs=500000)\n",
    "    clear_output(wait=True)\n",
    "    print(\"Entrenamiento finalizado...\")\n",
    "    print(\"Rate: \", rate)\n",
    "    print(\"Vuelta: \", vuelta + 1)\n",
    "    # Evaluamos la red neuronal para los datos de entrenamiento\n",
    "    res = clasif.predict(XRED)\n",
    "    cant_datos = XRED.shape[0]\n",
    "    mat_conf = [[0,0],[0,0]]\n",
    "    for i in range(0,XRED.shape[0]):\n",
    "        mat_conf[int(YRED[i])][int(res[i])] += 1\n",
    "    accuracy = (cant_datos - abs(res - YRED).sum())/cant_datos\n",
    "    print(\"Precisión entrenamiento:\", accuracy)\n",
    "    print(\"Matriz de confusión entrenamiento: \", mat_conf)\n",
    "\n",
    "    # Evaluamos la red neuronal para los datos de test (no cátedra)\n",
    "    res_test = clasif.predict(XTEST)\n",
    "    cant_datos_test = XTEST.shape[0]\n",
    "    mat_conf_test = [[0,0],[0,0]]\n",
    "    for i in range(0,XTEST.shape[0]):\n",
    "        mat_conf_test[int(YTEST[i])][int(res_test[i])] += 1\n",
    "    accuracy_test = (cant_datos_test - abs(res_test - YTEST).sum())/cant_datos_test\n",
    "    print(\"Precisión test (no cátedra):\", accuracy_test)\n",
    "    print(\"Matriz de confusión test (no cátedra): \", mat_conf_test)\n",
    "    diff_test = accuracy_test - ac_test_ant\n",
    "    diff = accuracy - ac_ant\n",
    "    ac_test_ant = accuracy_test\n",
    "    ac_ant = accuracy \n",
    "    \n",
    "    if diff > 0.001 or diff_test > 0.001:\n",
    "        rate /= 2\n",
    "    else:\n",
    "        rate *= 1.5\n",
    "    vuelta += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}